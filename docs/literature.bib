% Bibtex entries for Articulated body pose tracking project.

@article{johnson_composing_2016,
	title = {Composing graphical models with neural networks for structured representations and fast inference},
	url = {http://arxiv.org/abs/1603.06277},
	abstract = {We propose a general modeling and inference framework that combines the complementary strengths of probabilistic graphical models and deep learning methods. Our model family composes latent graphical models with neural network observation likelihoods. For inference, we use recognition networks to produce local evidence potentials, then combine them with the model distribution using efﬁcient message-passing algorithms. All components are trained simultaneously with a single stochastic variational inference objective. We illustrate this framework by automatically segmenting and categorizing mouse behavior from raw depth video, and demonstrate several other example models.},
	language = {en},
	urldate = {2019-02-18},
	journal = {arXiv:1603.06277 [stat]},
	author = {Johnson, Matthew J. and Duvenaud, David and Wiltschko, Alexander B. and Datta, Sandeep R. and Adams, Ryan P.},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.06277},
	keywords = {Statistics - Machine Learning},
	file = {Johnson et al. - 2016 - Composing graphical models with neural networks fo.pdf:/home/benjamin/Zotero/storage/EH7F4YMT/Johnson et al. - 2016 - Composing graphical models with neural networks fo.pdf:application/pdf}
}

@article{khan_conjugate-computation_2017,
	title = {Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models},
	url = {http://arxiv.org/abs/1703.04265},
	shorttitle = {Conjugate-Computation Variational Inference},
	abstract = {Variational inference is computationally challenging in models that contain both conjugate and non-conjugate terms. Methods speciﬁcally designed for conjugate models, even though computationally efﬁcient, ﬁnd it difﬁcult to deal with non-conjugate terms. On the other hand, stochastic-gradient methods can handle the nonconjugate terms but they usually ignore the conjugate structure of the model which might result in slow convergence. In this paper, we propose a new algorithm called Conjugate-computation Variational Inference ({CVI}) which brings the best of the two worlds together – it uses conjugate computations for the conjugate terms and employs stochastic gradients for the rest. We derive this algorithm by using a stochastic mirrordescent method in the mean-parameter space, and then expressing each gradient step as a variational inference in a conjugate model. We demonstrate our algorithm’s applicability to a large class of models and establish its convergence. Our experimental results show that our method converges much faster than the methods that ignore the conjugate structure of the model.},
	journaltitle = {{arXiv}:1703.04265 [cs]},
	author = {Khan, Mohammad Emtiyaz and Lin, Wu},
	urldate = {2019-02-19},
	date = {2017-03-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1703.04265},
	keywords = {Computer Science - Machine Learning},
	file = {Khan and Lin - 2017 - Conjugate-Computation Variational Inference  Conv.pdf:/home/benjamin/Zotero/storage/XV4F4ATZ/Khan and Lin - 2017 - Conjugate-Computation Variational Inference  Conv.pdf:application/pdf}
}

@article{linderman_recurrent_2016,
	title = {Recurrent switching linear dynamical systems},
	url = {http://arxiv.org/abs/1610.08466},
	abstract = {Many natural systems, such as neurons ﬁring in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems ({SLDS}), we present a new model class that not only discovers these dynamical units, but also explains how their switching behavior depends on observations or continuous latent states. These “recurrent” switching linear dynamical systems provide further insight by discovering the conditions under which each unit is deployed, something that traditional {SLDS} models fail to do. We leverage recent algorithmic advances in approximate inference to make Bayesian inference in these models easy, fast, and scalable.},
	journaltitle = {{arXiv}:1610.08466 [stat]},
	author = {Linderman, Scott W. and Miller, Andrew C. and Adams, Ryan P. and Blei, David M. and Paninski, Liam and Johnson, Matthew J.},
	urldate = {2019-02-19},
	date = {2016-10-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1610.08466},
	keywords = {Statistics - Machine Learning},
	file = {Linderman et al. - 2016 - Recurrent switching linear dynamical systems.pdf:/home/benjamin/Zotero/storage/348W2I5E/Linderman et al. - 2016 - Recurrent switching linear dynamical systems.pdf:application/pdf}
}

@article{lin_variational_2018,
	title = {Variational Message Passing with Structured Inference Networks},
	url = {http://arxiv.org/abs/1803.05589},
	abstract = {Recent efforts on combining deep models with probabilistic graphical models are promising in providing ﬂexible models that are also easy to interpret. We propose a variational message-passing algorithm for variational inference in such models. We make three contributions. First, we propose structured inference networks that incorporate the structure of the graphical model in the inference network of variational auto-encoders ({VAE}). Second, we establish conditions under which such inference networks enable fast amortized inference similar to {VAE}. Finally, we derive a variational message passing algorithm to perform efﬁcient naturalgradient inference while retaining the efﬁciency of the amortized inference. By simultaneously enabling structured, amortized, and natural-gradient inference for deep structured models, our method simpliﬁes and generalizes existing methods.},
	journaltitle = {{arXiv}:1803.05589 [stat]},
	author = {Lin, Wu and Hubacher, Nicolas and Khan, Mohammad Emtiyaz},
	urldate = {2019-02-19},
	date = {2018-03-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1803.05589},
	keywords = {Statistics - Machine Learning},
	file = {Lin et al. - 2018 - Variational Message Passing with Structured Infere.pdf:/home/benjamin/Zotero/storage/ZNAAGM75/Lin et al. - 2018 - Variational Message Passing with Structured Infere.pdf:application/pdf}
}

@article{xiao_simple_2018,
	title = {Simple Baselines for Human Pose Estimation and Tracking},
	url = {http://arxiv.org/abs/1804.06208},
	abstract = {There has been signiﬁcant progress on pose estimation and increasing interests on pose tracking in recent years. At the same time, the overall algorithm and system complexity increases as well, making the algorithm analysis and evaluation more diﬃcult. This work provides baseline methods that are surprisingly simple and eﬀective, thus helpful for inspiring and evaluating new ideas for the ﬁeld. State-of-the-art results are achieved on challenging benchmarks. The code will be released.},
	journaltitle = {{arXiv}:1804.06208 [cs]},
	author = {Xiao, Bin and Wu, Haiping and Wei, Yichen},
	urldate = {2018-07-13},
	date = {2018-04-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1804.06208},
	keywords = {toread, Computer Science - Computer Vision and Pattern Recognition, pose estimation},
	file = {Xiao et al. - 2018 - Simple Baselines for Human Pose Estimation and Tra.pdf:/home/benjamin/Zotero/storage/AMLSXML4/Xiao et al. - 2018 - Simple Baselines for Human Pose Estimation and Tra.pdf:application/pdf}
}
