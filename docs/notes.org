#+TITLE: Articulated Body Pose Tracking
#+latex_header: \usepackage[citestyle=authoryear-icomp,bibstyle=authoryear, hyperref=true,backref=true,maxcitenames=3,url=true,backend=biber,natbib=true] {biblatex}
#+latex_header: \addbibresource{literature.bib}


* Plan
1. Generate Ground Truth with Panda3D
   - Natural
   - Point light display
2. Test existing approaches
   - Find weak spots
3. Implement SVAE

* Review
Top down vs bottom up in Pose Estimation:
Top down: Detect and box human, and then track each box.
Bottom up: Search joint candidates, construct graph and partition.

** State of the art
 [@xiao_simple_2018]
*** Benchmarks
**** MPII Benchmark 
 http://human-pose.mpi-inf.mpg.de
 425 Gb
**** Posetrack
 https://posetrack.net
***** 2017
 33.5 Gb
***** 2018
 81.8 Gb
**** C(ommon) O(bjects in) Co(ntext)
 http://cocodataset.org
 Task: keypoint detection
** Open Questions
 - Do we need non-linear dynamics?
   If inducing-point and -value are given compute
   Jacobian and apply contraction theory:
   dynamics are contracting if absolute values of eigenvectors of the
   jacobian are all smaller than one.
   - Compare LDS with GPDM
** Current problems
*** 3D regression
It's not possible to aquire amount of training data for 
deep learning methods. Biggest Dataset available (Human3.6)
is recordings in laboratory environment.

* Ideas
- Use SVAE to extend vCGPDM
- Use constrained biomechanical model:
  Animators often control dofs to simulate physics,
  this should not be done by the CNS. 
- Build pose tracker working on natural *and* point-light display
- Do pose estimation on klt-tracked (or similar) features
- Vitruvian Man: Fit biomechanical skeleton into image by learning
  the transform matrix. Connection to hierarchy detection
  [@tenenbaum]
- build pose extraction algorithm that works on point light displays too
- make convolutional net recurrent
  make current frame input to next one like this:
  https://ai.googleblog.com/2018/03/mobile-real-time-video-segmentation.html
- Deep learning methods work really well for key point estimation 
  from single frames. Therefore people attempt to abuse 2D annotations.
** shared representation of biological movement and its perception using VAE-SMPs

* Literature
** @johnson_composing_2016
Graphical model with neural-network based observation-likelihoods
- @khan_conjugate-computation_2017:
  Generalizes to arbitrary conjugacy structure and removes need to run 
  conjugate part until convergence
- @linderman_recurrent_2016:
  This model has nonlinear transition/emission models
** @lin_variational_2018
Generalize and simplify SVAE [github: vmp-for-svae]
