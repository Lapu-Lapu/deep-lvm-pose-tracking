{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating pose from images using a deep conditional latent variable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from deep_lvm_pose_tracking import vae\n",
    "from deep_lvm_pose_tracking.vae import VAE\n",
    "from deep_lvm_pose_tracking import toy_data as toy\n",
    "from deep_lvm_pose_tracking import notebook_utils as nu\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Pytorch: Train with {device}')\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from IPython.display import HTML, display, Markdown\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# you might have to start the visdom server manually.\n",
    "cmd = sys.executable + ' -m visdom.server&'\n",
    "os.system(cmd)\n",
    "plotter = nu.VisdomLinePlotter(env_name='main')\n",
    "print(\"Started server on port:\", plotter.viz.port)\n",
    "\n",
    "import time\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem in its simplest form: introducing hierarchical toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 360000\n",
    "batch_size = 128\n",
    "d = 64  # image edge length\n",
    "img_shape = (d, d)\n",
    "\n",
    "bone_lengths, key_marker_width = nu.make_bonelengths_and_width()\n",
    "poses = nu.make_poses(N=N)\n",
    "\n",
    "# generate training data\n",
    "h = toy.HierarchyImages(angles=poses, bone_lengths=bone_lengths,\n",
    "                        key_marker_width=key_marker_width,\n",
    "                        img_shape=img_shape)\n",
    "\n",
    "# data loader for easy batching\n",
    "data_loader = DataLoader(h, batch_size=batch_size, shuffle=True, num_workers=4,\n",
    "                         drop_last=True)\n",
    "\n",
    "poses_val = nu.make_poses(N=N//10)\n",
    "\n",
    "h_val = toy.HierarchyImages(angles=poses_val, bone_lengths=bone_lengths,\n",
    "                            key_marker_width=key_marker_width,\n",
    "                            img_shape=img_shape)\n",
    "\n",
    "val_loader = DataLoader(h_val, batch_size=batch_size, shuffle=False, num_workers=4,\n",
    "                        drop_last=True)\n",
    "\n",
    "# dataloader dictionary with reduced validation set size\n",
    "dataloader = {'train': data_loader,\n",
    "              'val': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=N//5)),\n",
    "                               drop_last=True, batch_size=batch_size, num_workers=4),\n",
    "              'pretrain': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=N//5)),\n",
    "                               drop_last=True, batch_size=batch_size, num_workers=4)\n",
    "             }\n",
    "\n",
    "# bake notebook specific functions\n",
    "plot_sample_grid = partial(nu.plot_sample_grid, img_shape=img_shape)\n",
    "pose_to_image = partial(nu.pose_to_image, bone_lengths=bone_lengths, d=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: See end of notebook for video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_image(np.random.randint(0, len(poses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Latent Variable Model a.k.a. Variational Autoencoder\n",
    "\n",
    "We want to find the marginal likelihood of images $X$:\n",
    "\n",
    "$p(X) = \\int p(X|z)p(z) dz$.\n",
    "\n",
    "If $p(X|z)$ is a density parameterized by $\\eta = {NeuralNetwork}(z)$, we can not solve this integral analytically.\n",
    "We can still sample from $z$ to estimate $p(X)$, but X is super-high-dimensional, $p(X|z)$ will be practically zero for all for most samples of $z$, if we don't sample in a smart manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling $z$ from the posterior $p(z|X)$ would result in the most likely images, but we do not have the posterior.\n",
    "Let's introduce an approximation $Q(z)$ to the posterior such that $\\mathcal{KL}(Q(z)||P(z|X))$ is small:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{KL}[Q(z)||P(z|X)] &= \\mathbb{E}[\\log Q(z) - \\log P(z|X)]\\\\\n",
    "&= \\mathbb{E}[\\log Q(z) - \\log P(X|z) - \\log P(z)] + \\log P(X)\\\\\n",
    "&= \\mathbb{E}[- \\log P(X|z)] + \\mathcal{KL}[Q(z)|| P(z)] + \\log P(X)\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\Rightarrow\\log P(X) - \\mathcal{KL}[Q(z)||P(z|X)] &= \\mathbb{E}[\\log P(X|z)] - \\mathcal{KL}[Q(z)|| P(z)]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmV9OxiIOnL7"
   },
   "source": [
    "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/VAE.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli observation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\log P(X|z) = X\\log(\\text{NN}(z))+(1-X)\\log(1-\\text{NN}(z))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters are not optimized yet\n",
    "latent_dim = 3\n",
    "hidden = 600\n",
    "beta = 1\n",
    "\n",
    "model = VAE(input_dim=d**2, latent_dim=latent_dim,\n",
    "            hidden=hidden).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(vae.loss_function, likelihood='bernoulli')\n",
    "val_loss = vae.fit(model, dataloader, epochs=1, device=device, beta=beta, stop_crit=0, plotter=plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show $p(x|z)$ with $z \\sim \\mathcal{N}(0, 1)$.\n",
    "Even though there is room for improvement (e.g. changing the output activation function), I think the network learned the hierarchical constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_grid(nu.draw_samples(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing the latent space\n",
    "\n",
    "Maybe the 3 latent dimensions correspond to the angles already?\n",
    "$\\rightarrow$ Not quite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traverser = nu.LatentTraverser(model)\n",
    "anims = traverser.get_anims(range(3))\n",
    "vids = [anim.to_html5_video() for anim in anims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, vid in enumerate(vids):\n",
    "    display(Markdown(f\"#### Latent $z_{i}$\"))\n",
    "    display(HTML(vid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ly1YYFktOnMu"
   },
   "source": [
    "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/CVAE.png?raw=1)\n",
    "\n",
    "\\begin{align}\n",
    "p(x | z, c), q(t | x, c)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating poses given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating poses from images by training a shared latent variable model and then conditioning on the pose has some advantages:\n",
    "\n",
    "- Errorbars: it's a probabilistic model\n",
    "- Anomaly detection: $\\mathcal{KL}(q(z|x)|\\mathcal{N}(0, 1))$ will be large if input is very different than training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1 # one dimension is enough for this task!\n",
    "weight_fn = None\n",
    "beta = 1\n",
    "cvae = vae.cVAE(input_dim=3, condition_dim=d**2, latent_dim=latent_dim, hidden=600, likelihood='bernoulli',\n",
    "           condition_on='image').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(vae.joint_loss, likelihood='bernoulli')\n",
    "hist = vae.fit(cvae, dataloader, epochs=1, device=device, weight_fn=weight_fn,\n",
    "           loss_func=loss_func,\n",
    "           conditional=True, plotter=plotter, stop_crit=0, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw random poses from validation set\n",
    "idxs = np.random.choice(range(len(h_val)), size=9)\n",
    "poses = np.array([h_val[i]['angles'] for i in idxs])\n",
    "poses_degree = nu.un_normalize(poses)\n",
    "\n",
    "# draw corresponding images from validation set\n",
    "imgs = np.array([h_val[i]['image'] for i in idxs])\n",
    "# generate poses from noise given images\n",
    "samples = nu.draw_samples(cvae, imgs.reshape(9, d**2))\n",
    "\n",
    "poses_recovered = nu.un_normalize(samples[:, d**2:])\n",
    "np.std(poses_recovered-poses_degree, axis=0, ddof=1)\n",
    "\n",
    "for i in range(9):\n",
    "    label = samples[i, d**2:]\n",
    "    pose_true = poses_degree[i]\n",
    "    pose_recovered = nu.un_normalize(label)\n",
    "    print('Ground truth:\\n', pose_true)\n",
    "    print('Pose recovered from image:\\n', pose_recovered)\n",
    "    print('Error:\\n', pose_true-pose_recovered)\n",
    "    fig, ax = plt.subplots(ncols=2, sharey=True)\n",
    "    ax[0].set_title('pose (ground truth)')\n",
    "    ax[0].imshow(pose_to_image(poses[i]))\n",
    "    ax[1].set_title('pose|image')\n",
    "    ax[1].imshow(pose_to_image(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the one-dimensional latent space look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "T = time.time()\n",
    "td = timedelta(seconds=T-t0)\n",
    "print('Total runtime:', str(td).split('.')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepLVM]",
   "language": "python",
   "name": "conda-env-deepLVM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
