{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import Tensor as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "import toy_data as toy\n",
    "from vae import VAE, loss_function, cVAE\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from tqdm_utils import TqdmProgressCallback\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def plot_reconstruction(recon, orig):\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    ax[0].imshow(recon)\n",
    "    ax[1].imshow(orig)\n",
    "    ax[0].set_title('Reconstruction of an validation image.')\n",
    "    ax[1].set_title('Original')\n",
    "    plt.show()\n",
    "\n",
    "# Some parameters:\n",
    "N = 3600000  # number of observations\n",
    "batch_size = 32\n",
    "d = 64  # image edge length\n",
    "D = d**2\n",
    "img_shape = (d, d)\n",
    "print(f\"{N} points with {D} dimensions.\")\n",
    "\n",
    "# useful for plotting on a 3x3 grid:\n",
    "to_ind = np.array(list(product(range(3), range(3))))\n",
    "\n",
    "# setting up torch\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Train with {device}')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Images of hierarchical structures without time dependency\n",
    "\n",
    "Generate (d, d)-pixel images from 7 parameters: \n",
    "- 3 angles for each image, \n",
    "- 3 bone lengths and keypoint marker width shared for whole dataset. \n",
    "\n",
    "Origin of the 3-bone hierarchy is the central pixel.\n",
    "End of bones are marked by squared exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "eps = np.random.rand(3)\n",
    "bone_lengths = d//6 * (eps/2+1-1/3)\n",
    "print(\"Bone lengths:\", bone_lengths)\n",
    "key_marker_width = 1.5 * d/32\n",
    "labels = 1/2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "labels[:, 0] = labels[:, 0] * 4\n",
    "\n",
    "# generate training data\n",
    "h = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths,\n",
    "                        key_marker_width=key_marker_width,\n",
    "                        img_shape=img_shape)\n",
    "\n",
    "# data loader for easy batching\n",
    "data_loader = DataLoader(h, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# generate validation data\n",
    "labels_val = 1/2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "labels_val[:, 0] = labels_val[:, 0] * 4\n",
    "h_val = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths,\n",
    "                            key_marker_width=key_marker_width,\n",
    "                            img_shape=img_shape)\n",
    "\n",
    "val_loader = DataLoader(h, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# generate, encode, and decode new image for validation\n",
    "idx = np.random.randint(0, len(h_val))\n",
    "test_img = h_val[idx]['image']\n",
    "test_angles = h_val[idx]['angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_image(np.random.randint(0, len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset of data because of memory restriction\n",
    "idxs = np.random.choice(range(len(h)), replace=False, size=D)\n",
    "imgs = np.array([h[i]['image'] for i in idxs])\n",
    "X = np.reshape(imgs, (len(idxs), d**2))\n",
    "pca = PCA().fit(X)\n",
    "# n_comp = pca.n_components\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 components\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('First 9 principle components are fourier decomposition on a circle.')\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    comp = pca.components_[i].reshape(img_shape)\n",
    "    ax[x, y].imshow(comp)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pca.transform(test_img.ravel()[None])[:, :n_comp]\n",
    "\n",
    "recon_img = np.dot(w, pca.components_[:n_comp])[0].reshape(*img_shape)\n",
    "recon_img = recon_img + pca.mean_.reshape(*img_shape)\n",
    "\n",
    "plot_reconstruction(recon_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image from noise\n",
    "W = pca.transform(X)[:, :n_comp]\n",
    "\n",
    "# Using uniform noise because it matches the\n",
    "# statistics of w better than gauss\n",
    "\n",
    "min_w = W.min(axis=0)\n",
    "span = W.max(axis=0) - min_w\n",
    "\n",
    "n_examples = 6\n",
    "eps = np.random.rand(n_examples, n_comp)\n",
    "w_rand = span[None] * eps + min_w[None]\n",
    "\n",
    "generated = np.dot(w_rand, pca.components_[:n_comp])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=n_examples, sharey=True)\n",
    "fig.set_size_inches(n_examples*3, 3)\n",
    "ax[n_examples//2].set_title('Using weights sampled from \\nuniform distribution to generate image.')\n",
    "for i in range(n_examples): \n",
    "    ax[i].imshow(generated[i].reshape(*img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    hidden = L.Dense(code_size)\n",
    "    encoder.add(hidden)           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = build_pca_autoencoder(img_shape, n_comp)\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=imgs, y=imgs, epochs=7,\n",
    "#                 validation_data=[X_test, X_test],\n",
    "                callbacks=[TqdmProgressCallback()],\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, bias = encoder.get_weights()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('9 autoencoder components.')\n",
    "for i in range(9):\n",
    "    idx = np.random.randint(0, 100)\n",
    "    x, y = to_ind[i]\n",
    "    i = np.random.randint(0, W.shape[1])\n",
    "    ax[x, y].imshow(np.reshape(W[:, idx] + bias[idx], img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    s = keras.backend.get_session()\n",
    "    s.run(hidden, {input_1: test_img})\n",
    "    w = encoder(L.Input(test_img))\n",
    "    recon_img = reconstruction(w)\n",
    "    recon_img\n",
    "```\n",
    "\n",
    "-> I don't know how to access the hidden layer with keras. \n",
    "Therefore I switch to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.Linear(D, code_size)\n",
    "        self.decoder = nn.Linear(code_size, D)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, D))\n",
    "        return self.decode(w)\n",
    "\n",
    "def loss(recon_x, x):\n",
    "    return torch.mean((recon_x-x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LinearAutoencoder(code_size=n_comp)\n",
    "la.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(la.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = []\n",
    "for epoch in range(1):\n",
    "    with tqdm(data_loader, leave=True) as pbar:\n",
    "        for batch in pbar:\n",
    "            data = batch['image'].float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon = la(data.view(-1, D))\n",
    "            l = F.mse_loss(recon, data.view(-1, D))\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_losses.append(l)\n",
    "            pbar.set_description(f'Epoch {epoch}: MSE = {l:.5f}')\n",
    "        \n",
    "# plt.plot(train_losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = la(Tensor(test_img).view(-1, D).to(device)).cpu().detach().numpy().reshape(img_shape)\n",
    "plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = 3\n",
    "model = VAE(input_dim=D, bottleneck=bottleneck,\n",
    "            inter_dim=150).to(device)\n",
    "train_loss = model.fit(data_loader, epochs=1,\n",
    "                       verbose=True)\n",
    "\n",
    "plt.plot(train_loss[100:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck).to(device)\n",
    "    sample = model.decode(sample).cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "fig.set_size_inches((10, 10))\n",
    "for i, img in enumerate(sample):\n",
    "    ind = to_ind[i]\n",
    "    ax[ind[0], ind[1]].imshow(img.reshape(*img_shape))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon, mu,logvar = model(Tensor(test_img).to(device))\n",
    "print(mu)\n",
    "\n",
    "recon = recon.cpu().detach().numpy().reshape(img_shape)\n",
    "plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(ind):\n",
    "    mu_np = mu.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    for x in np.linspace(-4, 4):\n",
    "        mu_np[:, ind] = x\n",
    "        mu_star = Tensor(mu_np).to(device)\n",
    "        gen = model.decode(mu_star)\n",
    "        gen = gen.cpu().detach().numpy().reshape(img_shape)\n",
    "        yield (x, gen)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = h[0]['image']\n",
    "\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(img):\n",
    "    x, img = img\n",
    "    ax.set_title(f'{x:.3}')\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "vids = []\n",
    "for i in range(mu.shape[1]):\n",
    "    g = get_img(i)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=g, interval=120, \n",
    "                                   blit=True)\n",
    "    vids += [anim.to_html5_video()]\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, data_loader, epochs=5, max_iter=200, verbose=True):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for epoch in range(epochs):\n",
    "            with tqdm(data_loader) as pbar:\n",
    "                batch_idx = 0\n",
    "                for batch in pbar:\n",
    "                    batch_idx += 1\n",
    "                    if batch_idx > max_iter:\n",
    "                        print(\"Reached maximal number of iterations.\")\n",
    "                        break\n",
    "                    img = batch['image'].view(data_loader.batch_size, -1)\n",
    "                    label = batch['angles']\n",
    "                    batch = torch.cat((img, label), dim=1).float()\n",
    "                    data = T(batch).to(device).float()\n",
    "                    model.optimizer.zero_grad()\n",
    "                    recon_batch, mu, logvar = model(data)\n",
    "                    loss = loss_function(recon_batch, data.view(-1, D+3),\n",
    "                                         mu, logvar)\n",
    "                    loss.backward()\n",
    "                    train_loss += [loss.item()/len(data)]\n",
    "                    model.optimizer.step()\n",
    "                    if verbose:\n",
    "                        pbar.set_description(\n",
    "                            f\"Epoch {epoch}, Loss at batch {batch_idx:05d}: {loss.item()/len(data):.1f}\"\n",
    "                        )\n",
    "        return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = 3\n",
    "cvae = cVAE(input_dim=D+3, bottleneck=bottleneck,\n",
    "            cond_data_len=3,\n",
    "            hidden=150).to(device)\n",
    "\n",
    "hist = fit(cvae, data_loader, max_iter=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = np.concatenate((h[0]['image'].ravel(), h[0]['angles']))[None]\n",
    "\n",
    "recon, mu, logvar = cvae(T(test_np))\n",
    "image = recon.detach().numpy()[0, :D].reshape(d, d)\n",
    "angles = recon.detach().numpy()[0, D:]\n",
    "plot_reconstruction(image, h[0]['image'])\n",
    "a, b = h[0]['angles'], angles\n",
    "a/a.sum(), b/b.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "rbf_slow = gaussian_process.kernels.RBF(length_scale=5)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "GP_slow = gaussian_process.GaussianProcessRegressor(kernel=rbf_slow)\n",
    "\n",
    "N = 250\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, len(bone_lengths)))\n",
    "y[:, 0] = GP_slow.sample_y(t[:, None], random_state=None)[:, 0]*3\n",
    "for i in range(1, len(bone_lengths)):\n",
    "    y[:, i] = GP.sample_y(t[:, None], random_state=None)[:, 0]*0.7\n",
    "labels = y\n",
    "plt.plot(t, labels)\n",
    "\n",
    "# angles can not escape [-np.pi, np.pi]\n",
    "idx = abs(y) > np.pi\n",
    "y[idx] = y[idx] - 2*np.sign(y[idx])*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = toy.HierarchyImages(labels, bone_lengths, key_marker_width=key_marker_width, img_shape=img_shape)\n",
    "imgs = [h[i]['image'] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs), interval=60, \n",
    "                               blit=True)\n",
    "# anim.save(f'Toyproblem_unambiguous_{d}x{d}.mp4')\n",
    "html_video = anim.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
