{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import GPyOpt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import Tensor as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import toy_data as toy\n",
    "from vae import VAE, loss_function, cVAE, fit\n",
    "import vae as v\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from tqdm_utils import TqdmProgressCallback\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from contextlib import ExitStack\n",
    "from functools import partial\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# from notebook_utils import *\n",
    "import notebook_utils as nu\n",
    "\n",
    "# import GPyOpt\n",
    "\n",
    "# Some parameters:\n",
    "N = 3600000  # number of observations\n",
    "batch_size = 128\n",
    "d = 64  # image edge length\n",
    "D = d**2\n",
    "img_shape = (d, d)\n",
    "latent_dim = 4\n",
    "print(f\"{N} points with {D} dimensions.\")\n",
    "\n",
    "from functools import partial\n",
    "plot_sample_grid = partial(nu.plot_sample_grid, img_shape=img_shape)\n",
    "\n",
    "# don't forget to start visdom!\n",
    "plotter = nu.VisdomLinePlotter(env_name='main')\n",
    "\n",
    "# setting up torch\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Pytorch: Train with {device}')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Images of hierarchical structures without time dependency\n",
    "\n",
    "Generate (d, d)-pixel images from 7 parameters: \n",
    "- 3 angles for each image, \n",
    "- 3 bone lengths and keypoint marker width shared for whole dataset. \n",
    "\n",
    "Origin of the 3-bone hierarchy is the central pixel.\n",
    "End of bones are marked by squared exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "eps = np.random.rand(3)\n",
    "bone_lengths = d//6 * (eps/2+1-1/3)\n",
    "print(\"Bone lengths:\", bone_lengths)\n",
    "key_marker_width = 1.5 * d/32\n",
    "\n",
    "labels = 1/2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "labels[:, 0] = labels[:, 0] * 4\n",
    "\n",
    "# generate training data\n",
    "h = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths,\n",
    "                        key_marker_width=key_marker_width,\n",
    "                        img_shape=img_shape)\n",
    "\n",
    "# data loader for easy batching\n",
    "data_loader = DataLoader(h, batch_size=batch_size, shuffle=True, num_workers=4,\n",
    "                         drop_last=True)\n",
    "\n",
    "# generate validation data\n",
    "labels_val = 1/2*np.pi*(np.random.rand(N//10, 3)-0.5)\n",
    "labels_val[:, 0] = labels_val[:, 0] * 4\n",
    "\n",
    "h_val = toy.HierarchyImages(angles=labels_val, bone_lengths=bone_lengths,\n",
    "                            key_marker_width=key_marker_width,\n",
    "                            img_shape=img_shape)\n",
    "\n",
    "val_loader = DataLoader(h_val, batch_size=batch_size, shuffle=False, num_workers=4,\n",
    "                        drop_last=True)\n",
    "\n",
    "# dataloader dictionary with reduced validation set size\n",
    "dataloader = {'train': data_loader,\n",
    "              'val': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=N//5)),\n",
    "                               drop_last=True, batch_size=batch_size, num_workers=4),\n",
    "              'pretrain': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=N//5)),\n",
    "                               drop_last=True, batch_size=batch_size, num_workers=4)\n",
    "             }\n",
    "\n",
    "# dataloader with size comparable of PCA's datasize limit\n",
    "subsets = {k: Subset(h, np.random.choice(range(len(v)), size=5000)) for k, v in zip(['train', 'val'], [h, h_val])}\n",
    "reduced_dataloader = {k: DataLoader(subsets[k], batch_size=batch_size, drop_last=True) for k in subsets}\n",
    "\n",
    "# generate, encode, and decode new image for validation\n",
    "idx = np.random.randint(0, len(h_val))\n",
    "test_img = h_val[idx]['image']\n",
    "test_angles = h_val[idx]['angles']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: See end of notebook for video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_image(np.random.randint(0, len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset of data because of memory restriction\n",
    "idxs = np.random.choice(range(len(h)), replace=False, size=D)\n",
    "imgs = np.array([h[i]['image'] for i in idxs])\n",
    "X = np.reshape(imgs, (len(idxs), d**2))\n",
    "pca = PCA().fit(X)\n",
    "# n_comp = pca.n_components\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 components\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('First 9 principle components are fourier decomposition on a circle.')\n",
    "for i in range(9):\n",
    "    x, y = nu.to_ind[i]\n",
    "    comp = pca.components_[i].reshape(img_shape)\n",
    "    ax[x, y].imshow(comp)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pca.transform(test_img.ravel()[None])[:, :n_comp]\n",
    "\n",
    "recon_img = np.dot(w, pca.components_[:n_comp])[0].reshape(*img_shape)\n",
    "recon_img = recon_img + pca.mean_.reshape(*img_shape)\n",
    "nu.plot_reconstruction(recon_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = {'train': data_loader,\n",
    "#               'val': val_loader}\n",
    "\n",
    "loss = {}\n",
    "loss_pp = {}\n",
    "for phase in reduced_dataloader.keys():\n",
    "    loss[phase] = []\n",
    "    for data in tqdm(reduced_dataloader[phase]):\n",
    "        original = data['image'].view(-1, D).cpu().detach().numpy()\n",
    "        w = pca.transform(original)[:, :n_comp]\n",
    "        recon_img = np.dot(w, pca.components_[:n_comp])\n",
    "        loss[phase] += [(recon_img - original)**2]\n",
    "    loss_pp[phase] = np.mean(np.array(loss[phase]))\n",
    "    \n",
    "for k in reduced_dataloader.keys():\n",
    "    print(f'PCA {k} loss: {loss_pp[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image from noise\n",
    "W = pca.transform(X)[:, :n_comp]\n",
    "\n",
    "# Using uniform noise because it matches the\n",
    "# statistics of w better than gauss\n",
    "\n",
    "min_w = W.min(axis=0)\n",
    "span = W.max(axis=0) - min_w\n",
    "\n",
    "n_examples = 6\n",
    "eps = np.random.rand(n_examples, n_comp)\n",
    "w_rand = span[None] * eps + min_w[None]\n",
    "\n",
    "generated = np.dot(w_rand, pca.components_[:n_comp])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=n_examples, sharey=True)\n",
    "fig.set_size_inches(n_examples*3, 3)\n",
    "ax[n_examples//2].set_title('Using weights sampled from \\nuniform distribution to generate image.')\n",
    "for i in range(n_examples): \n",
    "    ax[i].imshow(generated[i].reshape(*img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder (PCA) and MLP Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.Linear(D, code_size)\n",
    "        self.decoder = nn.Linear(code_size, D)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, D))\n",
    "        return self.decode(w)\n",
    "    \n",
    "class MLPAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10, hidden=40):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Linear(D, hidden),\n",
    "            nn.Linear(hidden, code_size),\n",
    "            nn.Linear(D, code_size)\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.Linear(code_size, hidden),\n",
    "            nn.Linear(hidden, D),\n",
    "            nn.Linear(code_size, D)\n",
    "        ])\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # h = F.relu(self.encoder[0](x))\n",
    "        # return F.relu(self.encoder[1](h))\n",
    "        return F.relu(self.encoder[2](x))\n",
    "    \n",
    "    def decode(self, latent):\n",
    "        #h = F.relu(self.decoder[0](latent))\n",
    "        #return F.tanh(self.decoder[1](h))\n",
    "        return F.tanh(self.decoder[2](latent))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, D))\n",
    "        return self.decode(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 1000\n",
    "la = LinearAutoencoder(code_size=n_comp)\n",
    "la = MLPAutoencoder(code_size=n_comp)\n",
    "la.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(la.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = {}\n",
    "for epoch in range(1):\n",
    "    for phase in ['train', 'val']:\n",
    "        train_losses[phase] = []\n",
    "        with ExitStack() as stack:\n",
    "            pbar = stack.enter_context(tqdm(dataloader[phase], leave=True))\n",
    "            if phase == 'val':\n",
    "                stack.enter_context(torch.no_grad())\n",
    "                \n",
    "            i = -1\n",
    "            for batch in pbar:\n",
    "                i += 1\n",
    "                data = batch['image'].float().to(device)\n",
    "                recon = la(data.view(-1, D))\n",
    "                l = torch.mean((recon - data.view(-1, D))**2)\n",
    "                if phase == 'train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                train_losses[phase].append(l.cpu().detach().numpy())\n",
    "                pbar.set_description(f'({phase}) Epoch {epoch}: MSE = {l:.5f}')\n",
    "                \n",
    "                if i % 20 == 0:\n",
    "                    plotter.plot_image('recon', recon)\n",
    "                    plotter.plot_image('orig', data)\n",
    "        print(phase, np.mean(train_losses[phase]) if phase =='val' else train_losses[phase][-1])\n",
    "\n",
    "# plt.plot(train_losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = la(Tensor(test_img).view(-1, D).to(device)).cpu().detach().numpy().reshape(img_shape)\n",
    "nu.plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters are not optimized yet\n",
    "latent_dim = 3\n",
    "hidden = 600\n",
    "beta = 1\n",
    "\n",
    "model = VAE(input_dim=D, latent_dim=latent_dim,\n",
    "            hidden=hidden).to(device)\n",
    "\n",
    "loss_func = partial(v.loss_function, likelihood='bernoulli')\n",
    "val_loss = fit(model, dataloader, epochs=3, device=device, beta=beta, stop_crit=0, plotter=plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show $p(x|z)$ with $z \\sim \\mathcal{N}(0, 1)$.\n",
    "Even though there is room for improvement (e.g. changing the output activation function), I think the network learned the hierarchical constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_grid(nu.draw_samples(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing the latent space\n",
    "\n",
    "Maybe the 3 latent dimensions correspond to the angles already?\n",
    "$\\rightarrow$ Not quite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_lat = np.zeros((1, latent_dim))\n",
    "mu_np = mu_lat\n",
    "model.to(device)\n",
    "def get_img(ind):\n",
    "    # mu_np = mu_lat.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    for x in np.linspace(-4, 4):\n",
    "        mu_np[:, ind] = x\n",
    "        mu_star = Tensor(mu_np).to(device)\n",
    "        gen = model.decode(mu_star)[0]\n",
    "        gen = gen.cpu().detach().numpy().reshape(img_shape)\n",
    "        yield (x, gen)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = h[0]['image']\n",
    "\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(img):\n",
    "    x, img = img\n",
    "    ax.set_title(f'{x:.3}')\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = []\n",
    "for i in range(mu_lat.shape[1]):\n",
    "    g = get_img(i)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=g, interval=120, \n",
    "                                   blit=True)\n",
    "    vids += [anim.to_html5_video()]\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian observation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are required to make Gaussian VAE work with toydata:\n",
    "\n",
    "- PCA Trick: use weights of PCA as input\n",
    "- use optimized weight $\\beta$ for $\\mathcal{KL}(q(z|x) || p(z))$ Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following parameters have been found by GPyOpt for Gaussian VAE:\n",
    "latent_dim = 8\n",
    "hidden = 283\n",
    "beta = 0.89\n",
    "pca_dim = 525\n",
    "\n",
    "continue_training = False\n",
    "if continue_training:\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = VAE(input_dim=D, latent_dim=latent_dim, pre_dim=pca_dim,\n",
    "                hidden=hidden, likelihood='normal').to(device)\n",
    "    \n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# loss_func = partial(v.loss_function, beta=1, likelihood=model.likelihood)\n",
    "loss_func = v.joint_loss\n",
    "\n",
    "# model.to(device)\n",
    "save_weights = False\n",
    "weight_fn = 'gaussianVAEweights.pt' if save_weights else None\n",
    "\n",
    "# N = 15000\n",
    "dataloader = {'train': DataLoader(Subset(h, np.random.choice(range(len(h)), size=N)), num_workers=4,\n",
    "                                 drop_last=True, batch_size=batch_size),\n",
    "              'val': DataLoader(Subset(h_val, np.random.choice(range(len(h_val)), size=N//40)),\n",
    "                               drop_last=True, batch_size=batch_size),\n",
    "              'pretrain': DataLoader(Subset(h, np.random.choice(range(len(h_val)), size=N)),\n",
    "                               drop_last=True, batch_size=batch_size)\n",
    "             }\n",
    "# reduced_dataloader['pretrain'] = DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=1024)),\n",
    "#                            drop_last=True, batch_size=batch_size)\n",
    "\n",
    "val_loss = fit(model, dataloader, device=device,\n",
    "                epochs=3, loss_func=v.joint_loss, weight_fn=weight_fn,\n",
    "                plotter=plotter, stop_crit=0, beta=beta)\n",
    "\n",
    "plot_sample_grid(nu.draw_samples(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "test_input = test_img.ravel()[None]\n",
    "img_param, latent_param, pose_param, pre_param = model(Tensor(test_input).to('cpu'), pose=None)\n",
    "mu = img_param['mean'].cpu().detach().numpy().reshape(img_shape)\n",
    "nu.plot_reconstruction(mu, test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian VAE results still don't seem as good. Maybe I should just stick to mixing Bernoulli and Gaussian observations for images and pose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weights = False\n",
    "weight_fn = 'cvae_weights.pt' if save_weights else None\n",
    "latent_dim = 3\n",
    "beta = 0.89\n",
    "\n",
    "save_weights = False\n",
    "weight_fn = 'cvae_weights.pt' if save_weights else None\n",
    "\n",
    "# torch.save(cvae.state_dict(), weight_fn)\n",
    "# cvae.load_state_dict(torch.load(weight_fn))\n",
    "\n",
    "cvae = cVAE(input_dim=D, latent_dim=latent_dim, pose_dim=3, hidden=600, likelihood='bernoulli').to(device)\n",
    "\n",
    "loss_func = partial(v.joint_loss, likelihood='bernoulli')\n",
    "hist = fit(cvae, dataloader, epochs=8, device=device, weight_fn=weight_fn,\n",
    "           loss_func=loss_func,\n",
    "           conditional=True, plotter=plotter, stop_crit=0, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating images given labels\n",
    "\n",
    "It should be possible to generate images from noise conditioned on label. \n",
    "Even though conditioning removes some of the noise, it does not yet replicate\n",
    "the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(test_img)\n",
    "idxs = np.random.choice(range(len(h_val)), size=9)\n",
    "labels = np.array([h_val[i]['angles'] for i in idxs])\n",
    "samples = nu.draw_samples(cvae, labels)\n",
    "imgs = np.array([h_val[i]['image'] for i in idxs])\n",
    "# labels, samples[:, D:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    label = samples[i, D:]\n",
    "    img = samples[i, :D]\n",
    "    fig, ax = plt.subplots(ncols=2, sharey=True)\n",
    "    ax[0].set_title('label')\n",
    "    ax[0].imshow(imgs[i])\n",
    "    ax[1].set_title('img|label')\n",
    "    ax[1].imshow(img.reshape(d, d))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Adding time dependency\n",
    "\n",
    "If the VAE works well enough on simple, unambiguous single frame toy data, a VAE with recurrent latent space should be able to tackle ambigous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "rbf_slow = gaussian_process.kernels.RBF(length_scale=5)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "GP_slow = gaussian_process.GaussianProcessRegressor(kernel=rbf_slow)\n",
    "\n",
    "N = 250\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, len(bone_lengths)))\n",
    "y[:, 0] = GP_slow.sample_y(t[:, None], random_state=None)[:, 0]*3\n",
    "for i in range(1, len(bone_lengths)):\n",
    "    y[:, i] = GP.sample_y(t[:, None], random_state=None)[:, 0]*0.7\n",
    "labels = y\n",
    "plt.plot(t, labels)\n",
    "\n",
    "# angles can not escape [-np.pi, np.pi]\n",
    "idx = abs(y) > np.pi\n",
    "y[idx] = y[idx] - 2*np.sign(y[idx])*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = toy.HierarchyImages(labels, bone_lengths, key_marker_width=key_marker_width, img_shape=img_shape)\n",
    "imgs = [h[i]['image'] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs), interval=60, \n",
    "                               blit=True)\n",
    "# anim.save(f'Toyproblem_unambiguous_{d}x{d}.mp4')\n",
    "html_video = anim.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
