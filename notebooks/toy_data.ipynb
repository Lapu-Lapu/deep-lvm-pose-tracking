{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import Tensor as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import toy_data as toy\n",
    "from vae import VAE, loss_function, cVAE, fit\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from tqdm_utils import TqdmProgressCallback\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from contextlib import ExitStack\n",
    "\n",
    "def plot_reconstruction(recon, orig):\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    ax[0].imshow(recon)\n",
    "    ax[1].imshow(orig)\n",
    "    ax[0].set_title('Reconstruction of an validation image.')\n",
    "    ax[1].set_title('Original')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_sample_grid(sample):\n",
    "    assert len(sample) >= 9\n",
    "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "    fig.set_size_inches((10, 10))\n",
    "    for i in range(9):\n",
    "        img = sample[i]\n",
    "        ind = to_ind[i]\n",
    "        ax[ind[0], ind[1]].imshow(img.reshape(*img_shape))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Some parameters:\n",
    "N = 3600000  # number of observations\n",
    "batch_size = 512\n",
    "d = 64  # image edge length\n",
    "D = d**2\n",
    "img_shape = (d, d)\n",
    "print(f\"{N} points with {D} dimensions.\")\n",
    "\n",
    "# useful for plotting on a 3x3 grid:\n",
    "to_ind = np.array(list(product(range(3), range(3))))\n",
    "\n",
    "# setting up torch\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Pytorch: Train with {device}')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Images of hierarchical structures without time dependency\n",
    "\n",
    "Generate (d, d)-pixel images from 7 parameters: \n",
    "- 3 angles for each image, \n",
    "- 3 bone lengths and keypoint marker width shared for whole dataset. \n",
    "\n",
    "Origin of the 3-bone hierarchy is the central pixel.\n",
    "End of bones are marked by squared exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "eps = np.random.rand(3)\n",
    "bone_lengths = d//6 * (eps/2+1-1/3)\n",
    "print(\"Bone lengths:\", bone_lengths)\n",
    "key_marker_width = 1.5 * d/32\n",
    "labels = 1/2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "labels[:, 0] = labels[:, 0] * 4\n",
    "\n",
    "# generate training data\n",
    "h = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths,\n",
    "                        key_marker_width=key_marker_width,\n",
    "                        img_shape=img_shape)\n",
    "\n",
    "# data loader for easy batching\n",
    "data_loader = DataLoader(h, batch_size=batch_size, shuffle=True, num_workers=4,\n",
    "                         drop_last=True)\n",
    "\n",
    "# generate validation data\n",
    "labels_val = 1/2*np.pi*(np.random.rand(N//10, 3)-0.5)\n",
    "labels_val[:, 0] = labels_val[:, 0] * 4\n",
    "\n",
    "h_val = toy.HierarchyImages(angles=labels_val, bone_lengths=bone_lengths,\n",
    "                            key_marker_width=key_marker_width,\n",
    "                            img_shape=img_shape)\n",
    "\n",
    "val_loader = DataLoader(h_val, batch_size=batch_size, shuffle=False, num_workers=4,\n",
    "                        drop_last=True)\n",
    "\n",
    "# dataloader dictionary with reduced validation set size\n",
    "dataloader = {'train': data_loader,\n",
    "              'val': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=1024)),\n",
    "                               drop_last=True, batch_size=batch_size)}\n",
    "\n",
    "# dataloader with size comparable of PCA's datasize limit\n",
    "subsets = {k: Subset(h, np.random.choice(range(len(v)), size=5000)) for k, v in zip(['train', 'val'], [h, h_val])}\n",
    "reduced_dataloader = {k: DataLoader(subsets[k], batch_size=batch_size, drop_last=True) for k in subsets}\n",
    "\n",
    "# generate, encode, and decode new image for validation\n",
    "idx = np.random.randint(0, len(h_val))\n",
    "test_img = h_val[idx]['image']\n",
    "test_angles = h_val[idx]['angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_image(np.random.randint(0, len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset of data because of memory restriction\n",
    "idxs = np.random.choice(range(len(h)), replace=False, size=D)\n",
    "imgs = np.array([h[i]['image'] for i in idxs])\n",
    "X = np.reshape(imgs, (len(idxs), d**2))\n",
    "pca = PCA().fit(X)\n",
    "# n_comp = pca.n_components\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 components\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('First 9 principle components are fourier decomposition on a circle.')\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    comp = pca.components_[i].reshape(img_shape)\n",
    "    ax[x, y].imshow(comp)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pca.transform(test_img.ravel()[None])[:, :n_comp]\n",
    "\n",
    "recon_img = np.dot(w, pca.components_[:n_comp])[0].reshape(*img_shape)\n",
    "recon_img = recon_img + pca.mean_.reshape(*img_shape)\n",
    "plot_reconstruction(recon_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = {'train': data_loader,\n",
    "#               'val': val_loader}\n",
    "\n",
    "loss = {}\n",
    "loss_pp = {}\n",
    "for phase in reduced_dataloader.keys():\n",
    "    loss[phase] = []\n",
    "    for data in tqdm(reduced_dataloader[phase]):\n",
    "        original = data['image'].view(-1, D).cpu().detach().numpy()\n",
    "        w = pca.transform(original)[:, :n_comp]\n",
    "        recon_img = np.dot(w, pca.components_[:n_comp])\n",
    "        loss[phase] += [(recon_img - original)**2]\n",
    "    loss_pp[phase] = np.mean(np.array(loss[phase]))\n",
    "    \n",
    "for k in reduced_dataloader.keys():\n",
    "    print(f'PCA {k} loss: {loss_pp[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image from noise\n",
    "W = pca.transform(X)[:, :n_comp]\n",
    "\n",
    "# Using uniform noise because it matches the\n",
    "# statistics of w better than gauss\n",
    "\n",
    "min_w = W.min(axis=0)\n",
    "span = W.max(axis=0) - min_w\n",
    "\n",
    "n_examples = 6\n",
    "eps = np.random.rand(n_examples, n_comp)\n",
    "w_rand = span[None] * eps + min_w[None]\n",
    "\n",
    "generated = np.dot(w_rand, pca.components_[:n_comp])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=n_examples, sharey=True)\n",
    "fig.set_size_inches(n_examples*3, 3)\n",
    "ax[n_examples//2].set_title('Using weights sampled from \\nuniform distribution to generate image.')\n",
    "for i in range(n_examples): \n",
    "    ax[i].imshow(generated[i].reshape(*img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    hidden = L.Dense(code_size)\n",
    "    encoder.add(hidden)           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = build_pca_autoencoder(img_shape, n_comp)\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=imgs, y=imgs, epochs=7,\n",
    "#                 validation_data=[X_test, X_test],\n",
    "                callbacks=[TqdmProgressCallback()],\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, bias = encoder.get_weights()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('9 autoencoder components.')\n",
    "for i in range(9):\n",
    "    idx = np.random.randint(0, 100)\n",
    "    x, y = to_ind[i]\n",
    "    i = np.random.randint(0, W.shape[1])\n",
    "    ax[x, y].imshow(np.reshape(W[:, idx] + bias[idx], img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    s = keras.backend.get_session()\n",
    "    s.run(hidden, {input_1: test_img})\n",
    "    w = encoder(L.Input(test_img))\n",
    "    recon_img = reconstruction(w)\n",
    "    recon_img\n",
    "```\n",
    "\n",
    "-> I don't know how to access the hidden layer with keras. \n",
    "Therefore I switch to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.Linear(D, code_size)\n",
    "        self.decoder = nn.Linear(code_size, D)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, D))\n",
    "        return self.decode(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LinearAutoencoder(code_size=n_comp)\n",
    "la.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(la.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = {}\n",
    "for epoch in range(8):\n",
    "    for phase in ['train', 'val']:\n",
    "        train_losses[phase] = []\n",
    "        with ExitStack() as stack:\n",
    "            pbar = stack.enter_context(tqdm(dataloader[phase], leave=True))\n",
    "            if phase == 'val':\n",
    "                stack.enter_context(torch.no_grad())\n",
    "                \n",
    "            for batch in pbar:\n",
    "                data = batch['image'].float().to(device)\n",
    "                recon = la(data.view(-1, D))\n",
    "                l = torch.mean((recon - data.view(-1, D))**2)\n",
    "                if phase == 'train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                train_losses[phase].append(l.cpu().detach().numpy())\n",
    "                pbar.set_description(f'({phase}) Epoch {epoch}: MSE = {l:.5f}')\n",
    "        print(phase, np.mean(train_losses[phase]) if phase =='val' else train_losses[phase][-1])\n",
    "\n",
    "# plt.plot(train_losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = la(Tensor(test_img).view(-1, D).to(device)).cpu().detach().numpy().reshape(img_shape)\n",
    "plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = 3\n",
    "model = VAE(input_dim=D, bottleneck=bottleneck,\n",
    "            inter_dim=150).to(device)\n",
    "train_loss = model.fit(data_loader, epochs=1,\n",
    "                       verbose=True)\n",
    "\n",
    "# from vae import fit\n",
    "# model = VAE(input_dim=D, bottleneck=bottleneck,\n",
    "#             inter_dim=150).to(device)\n",
    "# model.beta = 1\n",
    "# train_loss = fit(model, dataloader, device=device, optimizer=optimizer,\n",
    "#                 epochs=1)\n",
    "\n",
    "plt.plot(train_loss[100:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck).to(device)\n",
    "    sample = model.decode(sample).cpu().numpy()\n",
    "plot_sample_grid(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon, mu,logvar = model(Tensor(test_img).to(device))\n",
    "print(mu)\n",
    "\n",
    "recon = recon.cpu().detach().numpy().reshape(img_shape)\n",
    "plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(ind):\n",
    "    mu_np = mu.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    for x in np.linspace(-4, 4):\n",
    "        mu_np[:, ind] = x\n",
    "        mu_star = Tensor(mu_np).to(device)\n",
    "        gen = model.decode(mu_star)\n",
    "        gen = gen.cpu().detach().numpy().reshape(img_shape)\n",
    "        yield (x, gen)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = h[0]['image']\n",
    "\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(img):\n",
    "    x, img = img\n",
    "    ax.set_title(f'{x:.3}')\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "vids = []\n",
    "for i in range(mu.shape[1]):\n",
    "    g = get_img(i)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=g, interval=120, \n",
    "                                   blit=True)\n",
    "    vids += [anim.to_html5_video()]\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def fit(model, data_loader, epochs=5, verbose=True, optimizer=None):\n",
    "    for epoch in range(epochs):\n",
    "        if optimizer is None:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "        for phase in ['train', 'val']:\n",
    "            epoch_loss = 0\n",
    "            N = len(data_loader[phase].dataset)\n",
    "            with ExitStack() as stack:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                    pbar = stack.enter_context(tqdm(data_loader['train']))\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    pbar = data_loader['val']\n",
    "                    stack.enter_context(torch.no_grad())\n",
    "                    \n",
    "                batch_idx = 0\n",
    "                for batch in pbar:\n",
    "                    batch_idx += 1\n",
    "                    img = batch['image'].view(data_loader[phase].batch_size, -1)\n",
    "                    label = batch['angles']\n",
    "                    batch = torch.cat((img, label), dim=1).float()\n",
    "                    data = T(batch).to(device).float()\n",
    "                    recon_batch, mu, logvar = model(data)\n",
    "                    loss = loss_function(recon_batch, data.view(-1, D+3),\n",
    "                                         mu, logvar, beta=model.beta)\n",
    "                    model.optimizer.zero_grad()\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        epoch_loss += loss.item()\n",
    "                        model.optimizer.step()\n",
    "                        if verbose:\n",
    "                            pbar.set_description(\n",
    "                                f\"Epoch {epoch}, Loss at batch {batch_idx:05d}: {loss.item()*N:.2E}\"\n",
    "                            )\n",
    "                    else:\n",
    "                        epoch_loss += loss.item()\n",
    "            if phase == 'train':\n",
    "                epoch_loss = loss.item()*N\n",
    "            print(f'{phase} loss: {epoch_loss*N:.2E}')\n",
    "            torch.save(model.state_dict(), weight_fn)\n",
    "```          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_fn = 'cvae_weights.pt'\n",
    "bottleneck = 8\n",
    "\n",
    "cvae = cVAE(input_dim=D+3, bottleneck=bottleneck,\n",
    "            cond_data_len=3,\n",
    "            hidden=1500).to(device)\n",
    "# cvae.to(device)\n",
    "\n",
    "# torch.save(cvae.state_dict(), weight_fn)\n",
    "cvae.load_state_dict(torch.load(weight_fn))\n",
    "\n",
    "optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "cvae.beta = 5\n",
    "hist = fit(cvae, dataloader, epochs=42, optimizer=optimizer, device=device, weight_fn=weight_fn,\n",
    "          conditional=True)\n",
    "plt.plot(hist[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.beta = 0.1\n",
    "test_np = np.concatenate((h_val[0]['image'].ravel(), h_val[0]['angles']))[None]\n",
    "\n",
    "optimizer=torch.optim.Adam(cvae.parameters(), lr=1e-2)\n",
    "\n",
    "# for beta in [0.1, 0.5, 1, 2, 5, 10]:\n",
    "cvae.to(device)\n",
    "for beta in [2]:\n",
    "#     cvae = cVAE(input_dim=D+3, bottleneck=bottleneck,\n",
    "#                 cond_data_len=3,\n",
    "#                 hidden=150).to(device)\n",
    "    cvae.beta = beta\n",
    "    hist = fit(cvae, dataloader, epochs=15, optimizer=optimizer,\n",
    "              device=device, conditional=True)\n",
    "\n",
    "    cvae.to('cpu')\n",
    "    recon, mu, logvar = cvae(T(test_np))\n",
    "    image = recon.cpu().detach().numpy()[0, :D].reshape(d, d)\n",
    "    angles = recon.cpu().detach().numpy()[0, D:]\n",
    "    plot_reconstruction(image, h_val[0]['image'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(9, bottleneck+3).to('cpu')\n",
    "        sample = cvae.decode(sample).cpu().numpy()\n",
    "\n",
    "    plot_sample_grid(sample[:, :D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = np.concatenate((h_val[0]['image'].ravel(), h_val[0]['angles']))[None]\n",
    "\n",
    "cvae.to('cpu')\n",
    "recon, mu, logvar = cvae(T(test_np))\n",
    "image = recon.cpu().detach().numpy()[0, :D].reshape(d, d)\n",
    "angles = recon.cpu().detach().numpy()[0, D:]\n",
    "plot_reconstruction(image, h[0]['image'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck+3).to('cpu')\n",
    "    sample = cvae.decode(sample).cpu().numpy()\n",
    "\n",
    "plot_sample_grid(sample[:, :D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "rbf_slow = gaussian_process.kernels.RBF(length_scale=5)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "GP_slow = gaussian_process.GaussianProcessRegressor(kernel=rbf_slow)\n",
    "\n",
    "N = 250\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, len(bone_lengths)))\n",
    "y[:, 0] = GP_slow.sample_y(t[:, None], random_state=None)[:, 0]*3\n",
    "for i in range(1, len(bone_lengths)):\n",
    "    y[:, i] = GP.sample_y(t[:, None], random_state=None)[:, 0]*0.7\n",
    "labels = y\n",
    "plt.plot(t, labels)\n",
    "\n",
    "# angles can not escape [-np.pi, np.pi]\n",
    "idx = abs(y) > np.pi\n",
    "y[idx] = y[idx] - 2*np.sign(y[idx])*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = toy.HierarchyImages(labels, bone_lengths, key_marker_width=key_marker_width, img_shape=img_shape)\n",
    "imgs = [h[i]['image'] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs), interval=60, \n",
    "                               blit=True)\n",
    "# anim.save(f'Toyproblem_unambiguous_{d}x{d}.mp4')\n",
    "html_video = anim.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
