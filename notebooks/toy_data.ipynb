{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "sys.path.append('../code')\n",
    "\n",
    "import toy_data as toy\n",
    "from vae import VAE\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "N = 2500\n",
    "batch_size = 32\n",
    "img_shape = (28, 28)\n",
    "\n",
    "from utils import TqdmProgressCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ind = np.array(list(product(range(3), range(3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_variance_imgs():\n",
    "    average = np.zeros((28, 28))\n",
    "    dev = np.zeros((28, 28))\n",
    "    labels = 2*np.pi*(np.random.rand(N, 2)-0.5)\n",
    "    batch_generator = list(toy.make_batch_generator(labels, [a,b], batch_size))\n",
    "    for i, (batch_img, _ ) in enumerate(batch_generator):\n",
    "        average = average + np.sum(batch_img[:, 0], axis=0)\n",
    "        dev = dev + np.sum(batch_img[:, 0]**2, axis=0)\n",
    "    average = average/i\n",
    "    dev = dev/i\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    ax[0].imshow(average)\n",
    "    ax[1].imshow(average**2-dev)\n",
    "# plot_mean_variance_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical images without time dependency\n",
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent across time\n",
    "a, b = (np.random.rand(2)+1)/2\n",
    "print(\"Bone lengths:\", a, b)\n",
    "labels = 2*np.pi*(np.random.rand(N, 2)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = toy.make_batch_generator(labels, [a,b], N)\n",
    "imgs, labels = batch_generator.__next__()\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(imgs, (N, 28**2))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    comp = pca.components_[i].reshape((28, 28))\n",
    "    ax[x, y].imshow(comp)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = toy.forward([-np.pi, -np.pi/2, -np.pi/2], [1, 1, 1])\n",
    "test_img = toy.keypoint_to_image(coords)\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    encoder.add(L.Dense(code_size))           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "    \n",
    "    return encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = build_pca_autoencoder((28, 28), n_comp)\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=imgs[:, 0], y=imgs[:, 0], epochs=15,\n",
    "#                 validation_data=[X_test, X_test],\n",
    "                callbacks=[TqdmProgressCallback()],\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, bias = encoder.get_weights()\n",
    "X[0].dot(W) + bias\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    i = np.random.randint(0, W.shape[1])\n",
    "    ax[x, y].imshow(np.reshape(W[:, i] + bias[i], (28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = toy.make_batch_generator(labels, [a,b], batch_size)\n",
    "device = torch.device(\"cpu\")\n",
    "bottleneck = 10\n",
    "model = VAE(bottleneck=bottleneck).to(device)\n",
    "train_loss = model.fit(batch_generator, max_iter=200)\n",
    "\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck).to(device)\n",
    "    sample = model.decode(sample).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "fig.set_size_inches((10, 10))\n",
    "for i, img in enumerate(np.array(sample)):\n",
    "    ind = to_ind[i]\n",
    "    ax[ind[0], ind[1]].imshow(img.reshape(28, 28))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical image date with time dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, 3))\n",
    "y[:, 0] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "y[:, 1] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "y[:, 2] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "labels = y\n",
    "plt.plot(t, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = (np.random.rand(3)+1)/2\n",
    "imgs = []\n",
    "for label in labels:\n",
    "    coords = toy.forward(label, [a, b, c])\n",
    "    imgs += [toy.keypoint_to_image(coords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[2*i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs)//2, interval=25, \n",
    "                               blit=True)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
