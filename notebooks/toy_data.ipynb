{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import Tensor as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import toy_data as toy\n",
    "from vae import VAE, loss_function, cVAE, fit\n",
    "import vae as v\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from tqdm_utils import TqdmProgressCallback\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from contextlib import ExitStack\n",
    "from functools import partial\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# from notebook_utils import *\n",
    "import notebook_utils as nu\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "# Some parameters:\n",
    "N = 3600000  # number of observations\n",
    "batch_size = 128\n",
    "d = 64  # image edge length\n",
    "D = d**2\n",
    "img_shape = (d, d)\n",
    "latent_dim = 4\n",
    "print(f\"{N} points with {D} dimensions.\")\n",
    "\n",
    "from functools import partial\n",
    "plot_sample_grid = partial(nu.plot_sample_grid, img_shape=img_shape)\n",
    "\n",
    "# don't forget to start visdom!\n",
    "plotter = nu.VisdomLinePlotter(env_name='main')\n",
    "\n",
    "# setting up torch\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Pytorch: Train with {device}')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Images of hierarchical structures without time dependency\n",
    "\n",
    "Generate (d, d)-pixel images from 7 parameters: \n",
    "- 3 angles for each image, \n",
    "- 3 bone lengths and keypoint marker width shared for whole dataset. \n",
    "\n",
    "Origin of the 3-bone hierarchy is the central pixel.\n",
    "End of bones are marked by squared exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "eps = np.random.rand(3)\n",
    "bone_lengths = d//6 * (eps/2+1-1/3)\n",
    "print(\"Bone lengths:\", bone_lengths)\n",
    "key_marker_width = 1.5 * d/32\n",
    "labels = 1/2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "labels[:, 0] = labels[:, 0] * 4\n",
    "\n",
    "# generate training data\n",
    "h = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths,\n",
    "                        key_marker_width=key_marker_width,\n",
    "                        img_shape=img_shape)\n",
    "\n",
    "# data loader for easy batching\n",
    "data_loader = DataLoader(h, batch_size=batch_size, shuffle=True, num_workers=4,\n",
    "                         drop_last=True)\n",
    "\n",
    "# generate validation data\n",
    "labels_val = 1/2*np.pi*(np.random.rand(N//10, 3)-0.5)\n",
    "labels_val[:, 0] = labels_val[:, 0] * 4\n",
    "\n",
    "h_val = toy.HierarchyImages(angles=labels_val, bone_lengths=bone_lengths,\n",
    "                            key_marker_width=key_marker_width,\n",
    "                            img_shape=img_shape)\n",
    "\n",
    "val_loader = DataLoader(h_val, batch_size=batch_size, shuffle=False, num_workers=4,\n",
    "                        drop_last=True)\n",
    "\n",
    "# dataloader dictionary with reduced validation set size\n",
    "dataloader = {'train': data_loader,\n",
    "              'val': DataLoader(torch.utils.data.Subset(h_val, np.random.choice(range(len(h_val)), size=1024)),\n",
    "                               drop_last=True, batch_size=batch_size)}\n",
    "\n",
    "# dataloader with size comparable of PCA's datasize limit\n",
    "subsets = {k: Subset(h, np.random.choice(range(len(v)), size=5000)) for k, v in zip(['train', 'val'], [h, h_val])}\n",
    "reduced_dataloader = {k: DataLoader(subsets[k], batch_size=batch_size, drop_last=True) for k in subsets}\n",
    "\n",
    "# generate, encode, and decode new image for validation\n",
    "idx = np.random.randint(0, len(h_val))\n",
    "test_img = h_val[idx]['image']\n",
    "test_angles = h_val[idx]['angles']\n",
    "# h.plot_image(np.random.randint(0, len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subset of data because of memory restriction\n",
    "idxs = np.random.choice(range(len(h)), replace=False, size=D)\n",
    "imgs = np.array([h[i]['image'] for i in idxs])\n",
    "X = np.reshape(imgs, (len(idxs), d**2))\n",
    "pca = PCA().fit(X)\n",
    "# n_comp = pca.n_components\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 components\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('First 9 principle components are fourier decomposition on a circle.')\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    comp = pca.components_[i].reshape(img_shape)\n",
    "    ax[x, y].imshow(comp)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pca.transform(test_img.ravel()[None])[:, :n_comp]\n",
    "\n",
    "recon_img = np.dot(w, pca.components_[:n_comp])[0].reshape(*img_shape)\n",
    "recon_img = recon_img + pca.mean_.reshape(*img_shape)\n",
    "plot_reconstruction(recon_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = {'train': data_loader,\n",
    "#               'val': val_loader}\n",
    "\n",
    "loss = {}\n",
    "loss_pp = {}\n",
    "for phase in reduced_dataloader.keys():\n",
    "    loss[phase] = []\n",
    "    for data in tqdm(reduced_dataloader[phase]):\n",
    "        original = data['image'].view(-1, D).cpu().detach().numpy()\n",
    "        w = pca.transform(original)[:, :n_comp]\n",
    "        recon_img = np.dot(w, pca.components_[:n_comp])\n",
    "        loss[phase] += [(recon_img - original)**2]\n",
    "    loss_pp[phase] = np.mean(np.array(loss[phase]))\n",
    "    \n",
    "for k in reduced_dataloader.keys():\n",
    "    print(f'PCA {k} loss: {loss_pp[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image from noise\n",
    "W = pca.transform(X)[:, :n_comp]\n",
    "\n",
    "# Using uniform noise because it matches the\n",
    "# statistics of w better than gauss\n",
    "\n",
    "min_w = W.min(axis=0)\n",
    "span = W.max(axis=0) - min_w\n",
    "\n",
    "n_examples = 6\n",
    "eps = np.random.rand(n_examples, n_comp)\n",
    "w_rand = span[None] * eps + min_w[None]\n",
    "\n",
    "generated = np.dot(w_rand, pca.components_[:n_comp])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=n_examples, sharey=True)\n",
    "fig.set_size_inches(n_examples*3, 3)\n",
    "ax[n_examples//2].set_title('Using weights sampled from \\nuniform distribution to generate image.')\n",
    "for i in range(n_examples): \n",
    "    ax[i].imshow(generated[i].reshape(*img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    hidden = L.Dense(code_size)\n",
    "    encoder.add(hidden)           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = build_pca_autoencoder(img_shape, n_comp)\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=imgs, y=imgs, epochs=7,\n",
    "#                 validation_data=[X_test, X_test],\n",
    "                callbacks=[TqdmProgressCallback()],\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, bias = encoder.get_weights()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('9 autoencoder components.')\n",
    "for i in range(9):\n",
    "    idx = np.random.randint(0, 100)\n",
    "    x, y = to_ind[i]\n",
    "    i = np.random.randint(0, W.shape[1])\n",
    "    ax[x, y].imshow(np.reshape(W[:, idx] + bias[idx], img_shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    s = keras.backend.get_session()\n",
    "    s.run(hidden, {input_1: test_img})\n",
    "    w = encoder(L.Input(test_img))\n",
    "    recon_img = reconstruction(w)\n",
    "    recon_img\n",
    "```\n",
    "\n",
    "-> I don't know how to access the hidden layer with keras. \n",
    "Therefore I switch to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.Linear(D, code_size)\n",
    "        self.decoder = nn.Linear(code_size, D)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, D))\n",
    "        return self.decode(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LinearAutoencoder(code_size=n_comp)\n",
    "la.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(la.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = {}\n",
    "for epoch in range(8):\n",
    "    for phase in ['train', 'val']:\n",
    "        train_losses[phase] = []\n",
    "        with ExitStack() as stack:\n",
    "            pbar = stack.enter_context(tqdm(dataloader[phase], leave=True))\n",
    "            if phase == 'val':\n",
    "                stack.enter_context(torch.no_grad())\n",
    "                \n",
    "            for batch in pbar:\n",
    "                data = batch['image'].float().to(device)\n",
    "                recon = la(data.view(-1, D))\n",
    "                l = torch.mean((recon - data.view(-1, D))**2)\n",
    "                if phase == 'train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                train_losses[phase].append(l.cpu().detach().numpy())\n",
    "                pbar.set_description(f'({phase}) Epoch {epoch}: MSE = {l:.5f}')\n",
    "        print(phase, np.mean(train_losses[phase]) if phase =='val' else train_losses[phase][-1])\n",
    "\n",
    "# plt.plot(train_losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = la(Tensor(test_img).view(-1, D).to(device)).cpu().detach().numpy().reshape(img_shape)\n",
    "plot_reconstruction(recon, test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(input_dim=D, latent_dim=latent_dim,\n",
    "            hidden=1000).to(device)\n",
    "\n",
    "loss_func = partial(v.loss_function, beta=1, likelihood='bernoulli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check loss function\n",
    "mu_x = 0*torch.ones((batch_size, D+3))\n",
    "var_x = 1*torch.ones((batch_size, D+3))\n",
    "x = torch.ones((batch_size, D+3))\n",
    "mu = torch.zeros((batch_size, latent_dim))\n",
    "logvar = torch.zeros((batch_size, latent_dim))\n",
    "loss_func = partial(v.loss_function, beta=1, likelihood='normal')\n",
    "loss_func(decoded=(mu_x, var_x), x=x, mu=mu, logvar=logvar)\n",
    "# batch_size*(D+3)*0.5*np.log(np.pi*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "continue_training = False\n",
    "if continue_training:\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = VAE(input_dim=D, latent_dim=latent_dim,\n",
    "                hidden=900, likelihood='bernoulli').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_func = partial(v.loss_function, beta=1, likelihood=model.likelihood)\n",
    "\n",
    "# model.to(device)\n",
    "save_weights = False\n",
    "weight_fn = 'gaussianVAEweights.pt' if save_weights else None\n",
    "train_loss = fit(model, dataloader, device=device, optimizer=optimizer,\n",
    "                epochs=3, loss_func=loss_func, weight_fn=weight_fn,\n",
    "                plotter=plotter)\n",
    "\n",
    "skip = min(100, len(train_loss))\n",
    "plt.plot(train_loss[skip:])\n",
    "plt.show()\n",
    "plot_sample_grid(nu.draw_samples(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "test_input = test_img.ravel()[None]\n",
    "mu_out, var_out, mu_lat, logvar_lat = model(Tensor(test_input).to('cpu'))\n",
    "\n",
    "print(mu_out)\n",
    "print(var_out)\n",
    "\n",
    "# var = var_out.cpu().detach().numpy().reshape(img_shape)\n",
    "mu = mu_out.cpu().detach().numpy().reshape(img_shape)\n",
    "nu.plot_reconstruction(mu, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def get_img(ind):\n",
    "    mu_np = mu_lat.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    for x in np.linspace(-4, 4):\n",
    "        mu_np[:, ind] = x\n",
    "        mu_star = Tensor(mu_np).to(device)\n",
    "        gen = model.decode(mu_star)[0]\n",
    "        gen = gen.cpu().detach().numpy().reshape(img_shape)\n",
    "        yield (x, gen)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = h[0]['image']\n",
    "\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(img):\n",
    "    x, img = img\n",
    "    ax.set_title(f'{x:.3}')\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = []\n",
    "for i in range(mu_lat.shape[1]):\n",
    "    g = get_img(i)\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=g, interval=120, \n",
    "                                   blit=True)\n",
    "    vids += [anim.to_html5_video()]\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vids[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_weights = False\n",
    "weight_fn = 'cvae_weights.pt' if save_weights else None\n",
    "latent_dim = 8\n",
    "\n",
    "cvae = cVAE(input_dim=D, latent_dim=latent_dim,\n",
    "            pose_dim=3, likelihood='bernoulli',\n",
    "            hidden=1500).to(device)\n",
    "cvae.to(device)\n",
    "\n",
    "# torch.save(cvae.state_dict(), weight_fn)\n",
    "# cvae.load_state_dict(torch.load(weight_fn))\n",
    "\n",
    "cvae.to('cuda')\n",
    "optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "# loader = dataloader.copy()\n",
    "# loader['train'] = DataLoader(Subset(h, np.random.choice(range(len(h)), size=int(1e4))))\n",
    "hist = fit(cvae, dataloader, epochs=3, optimizer=optimizer, device=device, weight_fn=weight_fn,\n",
    "          conditional=True, plotter=plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(test_img)\n",
    "labels = np.array([h_val[i]['angles'] for i in range(9)])\n",
    "samples = nu.draw_samples(cvae, labels)\n",
    "# plot_sample_grid(samples[:, :D])\n",
    "\n",
    "imgs = np.array([h_val[i]['image'] for i in range(9)])\n",
    "# plot_sample_grid(imgs)\n",
    "\n",
    "labels, samples[:, D:]\n",
    "labels.max(), 2*np.pi*(samples[:, D:].max()-0.5)\n",
    "for orig, sample in zip(labels, samples[:, :]):\n",
    "    label = sample[D:]\n",
    "    img = sample[:D]\n",
    "    fig, ax = plt.subplots(ncols=3, sharey=True)\n",
    "    ax[0].set_title('orig')\n",
    "    ax[0].imshow(toy.keypoint_to_image(toy.forward(orig, bone_lengths), size=(d, d), include_origin=True))\n",
    "    ax[1].set_title('mu_label')\n",
    "    ax[1].imshow(toy.keypoint_to_image(toy.forward(label, bone_lengths), size=(d, d), include_origin=True))\n",
    "    ax[2].set_title('mu_img')\n",
    "    ax[2].imshow(img.reshape(d, d))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.1\n",
    "latent_dim = 12\n",
    "cvae = cVAE(input_dim=D, latent_dim=int(latent_dim),\n",
    "            pose_dim=3, likelihood='bernoulli',\n",
    "            hidden=1500).to(device)\n",
    "plotter = nu.VisdomLinePlotter(env_name='main')\n",
    "val_loss = fit(cvae, reduced_dataloader, epochs=3, device=device, weight_fn=weight_fn,\n",
    "          conditional=True, plotter=plotter, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def f(inp):\n",
    "    beta = inp[0, 0]\n",
    "    latent_dim = inp[0, 1]\n",
    "    print(beta, latent_dim)\n",
    "    cvae = cVAE(input_dim=D, latent_dim=int(latent_dim),\n",
    "                pose_dim=3, likelihood='bernoulli',\n",
    "                hidden=1500).to(device)\n",
    "    val_loss = fit(cvae, reduced_dataloader, epochs=3, device=device, \n",
    "                   # weight_fn=f'beta{beta:.2f}dim{latent_dim}.pt',\n",
    "                   weight_fn=None,\n",
    "              conditional=True, plotter=plotter, beta=beta)\n",
    "    del cvae\n",
    "    torch.cuda.empty_cache()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = nu.VisdomLinePlotter(env_name='main')\n",
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0.5,20)},\n",
    "          {'name': 'var_2', 'type': 'discrete', 'domain': (3, 10)}]\n",
    "opt = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, num_cores=4, model_type='GP_MCMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cvae\n",
    "model.to('cpu')\n",
    "z, logvar = model.encode(T(test_np))\n",
    "sample = torch.randn(9, model.enc[-1].out_features//2).to('cpu')\n",
    "obs = T(np.repeat(h_val[0]['angles'][None], 9, axis=0))\n",
    "obs.shape, sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, var_x = model.decode(sample, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample.detach().numpy()[0, :D].reshape(d, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.to('cpu')\n",
    "with torch.no_grad():\n",
    "    test_np = np.concatenate((h_val[0]['image'].ravel(), h_val[0]['angles']))[None]\n",
    "    z, logvar = cvae.encode(T(test_np))\n",
    "    x, var_x = cvae.decode(z, T(h_val[0]['angles'][None]))\n",
    "plt.imshow(x[:, :D].reshape(d, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.beta = 0.1\n",
    "test_np = np.concatenate((h_val[0]['image'].ravel(), h_val[0]['angles']))[None]\n",
    "\n",
    "optimizer=torch.optim.Adam(cvae.parameters(), lr=1e-2)\n",
    "\n",
    "# for beta in [0.1, 0.5, 1, 2, 5, 10]:\n",
    "cvae.to(device)\n",
    "for beta in [2]:\n",
    "#     cvae = cVAE(input_dim=D+3, bottleneck=bottleneck,\n",
    "#                 cond_data_len=3,\n",
    "#                 hidden=150).to(device)\n",
    "    cvae.beta = beta\n",
    "    hist = fit(cvae, dataloader, epochs=15, optimizer=optimizer,\n",
    "              device=device, conditional=True)\n",
    "\n",
    "    cvae.to('cpu')\n",
    "    recon, mu, logvar = cvae(T(test_np))\n",
    "    image = recon.cpu().detach().numpy()[0, :D].reshape(d, d)\n",
    "    angles = recon.cpu().detach().numpy()[0, D:]\n",
    "    plot_reconstruction(image, h_val[0]['image'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(9, bottleneck+3).to('cpu')\n",
    "        sample = cvae.decode(sample).cpu().numpy()\n",
    "\n",
    "    plot_sample_grid(sample[:, :D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = np.concatenate((h_val[0]['image'].ravel(), h_val[0]['angles']))[None]\n",
    "\n",
    "cvae.to('cpu')\n",
    "recon, mu, logvar = cvae(T(test_np))\n",
    "image = recon.cpu().detach().numpy()[0, :D].reshape(d, d)\n",
    "angles = recon.cpu().detach().numpy()[0, D:]\n",
    "plot_reconstruction(image, h[0]['image'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck+3).to('cpu')\n",
    "    sample = cvae.decode(sample).cpu().numpy()\n",
    "\n",
    "plot_sample_grid(sample[:, :D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "rbf_slow = gaussian_process.kernels.RBF(length_scale=5)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "GP_slow = gaussian_process.GaussianProcessRegressor(kernel=rbf_slow)\n",
    "\n",
    "N = 250\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, len(bone_lengths)))\n",
    "y[:, 0] = GP_slow.sample_y(t[:, None], random_state=None)[:, 0]*3\n",
    "for i in range(1, len(bone_lengths)):\n",
    "    y[:, i] = GP.sample_y(t[:, None], random_state=None)[:, 0]*0.7\n",
    "labels = y\n",
    "plt.plot(t, labels)\n",
    "\n",
    "# angles can not escape [-np.pi, np.pi]\n",
    "idx = abs(y) > np.pi\n",
    "y[idx] = y[idx] - 2*np.sign(y[idx])*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = toy.HierarchyImages(labels, bone_lengths, key_marker_width=key_marker_width, img_shape=img_shape)\n",
    "imgs = [h[i]['image'] for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs), interval=60, \n",
    "                               blit=True)\n",
    "# anim.save(f'Toyproblem_unambiguous_{d}x{d}.mp4')\n",
    "html_video = anim.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
