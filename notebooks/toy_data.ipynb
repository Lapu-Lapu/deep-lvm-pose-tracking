{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "import keras\n",
    "L = keras.layers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "import toy_data as toy\n",
    "from vae import VAE\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "\n",
    "from tqdm_utils import TqdmProgressCallback\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Some parameters:\n",
    "N = 2500  # number of observations\n",
    "batch_size = 32\n",
    "d = 28  # image edge length\n",
    "D = d**2\n",
    "img_shape = (d, d)\n",
    "\n",
    "# useful for plotting on a 3x3 grid:\n",
    "to_ind = np.array(list(product(range(3), range(3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy data: Images of hierarchical structures without time dependency\n",
    "\n",
    "Generate (d, d)-pixel images from 7 parameters: \n",
    "- 3 angles for each image, \n",
    "- 3 bone lengths and keypoint marker width shared for whole dataset. \n",
    "\n",
    "Origin of the 3-bone hierarchy is the central pixel.\n",
    "End of bones are marked by squared exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "bone_lengths = d//3*(np.random.rand(3)+1)/2\n",
    "\n",
    "print(\"Bone lengths:\", bone_lengths)\n",
    "key_marker_width = 1\n",
    "labels = 2*np.pi*(np.random.rand(N, 3)-0.5)\n",
    "h = toy.HierarchyImages(angles=labels, bone_lengths=bone_lengths, key_marker_width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # using batch generator for possibly huge dataset\n",
    "    batch_generator = toy.make_batch_generator(labels, bone_lengths, N)\n",
    "    imgs, labels = batch_generator.__next__()\n",
    "    print('imgs.shape:', imgs.shape)\n",
    "    plt.imshow(imgs[0, 0])\n",
    "    plt.title('Example of toy data image with 3 bones.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_image(np.random.randint(0, len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array([h[i]['image'] for i in range(len(labels))])\n",
    "labels = np.array([h[i]['angles'] for i in range(len(labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(imgs, (N, 28**2))\n",
    "pca = PCA().fit(X)\n",
    "\n",
    "vexpl = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(vexpl)\n",
    "thresh = 0.95\n",
    "n_comp = np.where(vexpl > thresh)[0][0]\n",
    "plt.vlines(n_comp, 0, 1, linestyles='dotted')\n",
    "plt.hlines(thresh, 0, 800, linestyles='dotted')\n",
    "plt.title(f'{n_comp} components explain {thresh} of the variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 9 components\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('First 9 principle components are fourier decomposition on a circle.')\n",
    "for i in range(9):\n",
    "    x, y = to_ind[i]\n",
    "    comp = pca.components_[i].reshape((28, 28))\n",
    "    ax[x, y].imshow(comp)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate, encode, and decode new image for validation\n",
    "coords = toy.forward([-np.pi, -np.pi/2, -np.pi/2], [1, 1, 1])\n",
    "test_img = toy.keypoint_to_image(coords)\n",
    "test_img.flatten()[None].shape\n",
    "w = pca.fit_transform(X)[:, :n_comp]\n",
    "\n",
    "idx = np.random.randint(0, N)\n",
    "recon_img = np.dot(w, pca.components_[:n_comp])[idx].reshape(28, 28)\n",
    "plt.imshow(recon_img)\n",
    "plt.title('Reconstruction of an validation image.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image from noise\n",
    "w_rand = np.random.multivariate_normal(np.zeros(n_comp), np.diag(w.var(axis=0)))\n",
    "plt.imshow(np.dot(w_rand, pca.components_[:n_comp]).reshape(28, 28))\n",
    "plt.title('Using weights sampled from normal distribution to generate image.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA by autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca_autoencoder(img_shape, code_size):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Flatten())                  #flatten image to vector\n",
    "    hidden = L.Dense(code_size)\n",
    "    encoder.add(hidden)           #actual encoder\n",
    "\n",
    "    decoder = keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
    "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = build_pca_autoencoder((28, 28), n_comp)\n",
    "inp = L.Input(img_shape)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "autoencoder.fit(x=imgs, y=imgs, epochs=15,\n",
    "#                 validation_data=[X_test, X_test],\n",
    "#                 callbacks=[TqdmProgressCallback()],\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, bias = encoder.get_weights()\n",
    "X[0].dot(W) + bias\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "ax[0, 1].set_title('9 autoencoder components.')\n",
    "for i in range(9):\n",
    "    idx = np.random.randint(0, 100)\n",
    "    x, y = to_ind[i]\n",
    "    i = np.random.randint(0, W.shape[1])\n",
    "    ax[x, y].imshow(np.reshape(W[:, idx] + bias[idx], (28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate, encode, and decode new image for validation\n",
    "coords = toy.forward([-np.pi, -np.pi/2, -np.pi/2], [10, 10, 10])\n",
    "test_img = toy.keypoint_to_image(coords)\n",
    "test_img.flatten()[None].shape\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    s = keras.backend.get_session()\n",
    "    s.run(hidden, {input_1: test_img})\n",
    "    w = encoder(L.Input(test_img))\n",
    "    recon_img = reconstruction(w)\n",
    "    recon_img\n",
    "```\n",
    "\n",
    "-> I don't know how to access the hidden layer with keras. \n",
    "Therefore I switch to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder: Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, code_size=10):\n",
    "        nn.Module.__init__(self)\n",
    "        self.encoder = nn.Linear(784, code_size)\n",
    "        self.decoder = nn.Linear(code_size, 784)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w = self.encode(x.view(-1, 784))\n",
    "        return self.decode(w)\n",
    "\n",
    "def loss(recon_x, x):\n",
    "    return torch.mean((recon_x-x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LinearAutoencoder()\n",
    "data_loader = DataLoader(h, batch_size=64)\n",
    "optimizer = SGD(la.parameters(), lr=1e-3)\n",
    "device = torch.device('cuda')\n",
    "train_losses = []\n",
    "for epoch in range(100):\n",
    "    for batch in data_loader:\n",
    "        data = batch['image'].float()\n",
    "        optimizer.zero_grad()\n",
    "        recon = la(data.view(-1, 784))\n",
    "        l = loss(recon, data.view(-1, 784))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(la(Tensor(test_img)).view(28,28).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = toy.make_batch_generator(labels, [a,b, c], batch_size)\n",
    "device = torch.device(\"cpu\")\n",
    "bottleneck = 10\n",
    "model = VAE(bottleneck=bottleneck).to(device)\n",
    "train_loss = model.fit(batch_generator, max_iter=200,\n",
    "                      verbose=False)\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample = torch.randn(9, bottleneck).to(device)\n",
    "    sample = model.decode(sample).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "fig.set_size_inches((10, 10))\n",
    "for i, img in enumerate(np.array(sample)):\n",
    "    ind = to_ind[i]\n",
    "    ax[ind[0], ind[1]].imshow(img.reshape(28, 28))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical image date with time dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce time dependency\n",
    "rbf = gaussian_process.kernels.RBF(length_scale=2)\n",
    "GP = gaussian_process.GaussianProcessRegressor(kernel=rbf)\n",
    "\n",
    "t = np.linspace(0, 120, N)\n",
    "y = np.empty((N, 3))\n",
    "y[:, 0] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "y[:, 1] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "y[:, 2] = GP.sample_y(t[:, None], random_state=None)[:, 0]\n",
    "labels = y\n",
    "plt.plot(t, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = 20//3*(np.random.rand(3)+1)/2\n",
    "imgs = []\n",
    "for label in labels:\n",
    "    coords = toy.forward(label, [a, b, c])\n",
    "    imgs += [toy.keypoint_to_image(coords, include_origin=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "img = imgs[0]\n",
    "mimg = plt.imshow(img)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "def animate(i):\n",
    "    img = imgs[2*i]\n",
    "    mimg.set_data(img)\n",
    "    return (mimg,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=len(imgs)//2, interval=25, \n",
    "                               blit=True)\n",
    "# anim.save('Toyproblem.mp4')\n",
    "html_video = anim.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
